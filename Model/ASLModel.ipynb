{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e0d4027712622d",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:05:50.157917Z",
     "start_time": "2025-03-05T02:05:50.155259Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "be0ea784f803fef7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:05:50.490108Z",
     "start_time": "2025-03-05T02:05:50.487533Z"
    }
   },
   "source": [
    "from Model.Network import Network\n",
    "from Layers.MaxPooling import MaxPooling\n",
    "from Layers.FullyConnected import FullyConnected\n",
    "from Layers.Convolution import Convolution\n",
    "from Loss.CrossEntropyLossFunction import CrossEntropyLossFunction\n",
    "from Activation.Softmax import Softmax\n",
    "from Layers.Flatten import Flatten\n",
    "from Activation.ReLU import ReLU"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "id": "eaaf6dd5e662fcb4",
   "metadata": {},
   "source": [
    "Preprocess Images"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:06:27.660277Z",
     "start_time": "2025-03-05T02:06:27.657903Z"
    }
   },
   "cell_type": "code",
   "source": "image_shape = (28,28)",
   "id": "608c4477bb7d8be",
   "outputs": [],
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "id": "e5f039b86c93814b",
   "metadata": {},
   "source": [
    "Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "87f3b5623be1a563",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:06:28.702975Z",
     "start_time": "2025-03-05T02:06:28.699512Z"
    }
   },
   "source": [
    "data_path = '/Users/aaryanpatel/Documents/ComputerScience/CSC590MachineLearning/ASL-CNN/asl_dataset'\n",
    "\n",
    "# Sort the folders in the dataset in alphabetical order\n",
    "classes = sorted(os.listdir(data_path))\n",
    "\n",
    "# Create dictionary mapping classes to indexes\n",
    "class_index_dict = {}\n",
    "for index, clas in enumerate(classes):\n",
    "    class_index_dict[clas] = index"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "id": "1fe6916bb8f19b6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:06:30.043323Z",
     "start_time": "2025-03-05T02:06:29.115154Z"
    }
   },
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Extract the images and labels (using the created dictionary) of each subdirectory in the dataset\n",
    "for folder in classes:\n",
    "    folder_dir = os.path.join(data_path, folder)\n",
    "\n",
    "    for image in os.listdir(folder_dir):\n",
    "        img_path = os.path.join(folder_dir, image)\n",
    "\n",
    "        # Read, resize, and normalize the image\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, image_shape)\n",
    "        image = image / 255.0\n",
    "\n",
    "        images.append(image)\n",
    "        labels.append(class_index_dict[folder])"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "id": "16ce4530d3165e09",
   "metadata": {},
   "source": [
    "Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "d0c66ae7b4df5e5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:06:30.245272Z",
     "start_time": "2025-03-05T02:06:30.239305Z"
    }
   },
   "source": [
    "# Reshape the images to create the x_data\n",
    "\n",
    "x_data = np.array(images).reshape(-1, 1, image_shape[0], image_shape[1])"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "id": "2da25a11f4869769",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:06:30.721080Z",
     "start_time": "2025-03-05T02:06:30.718507Z"
    }
   },
   "source": [
    "# One-hot-encode the labels to create the y_data\n",
    "\n",
    "y_data = np.zeros((len(labels), len(classes)))\n",
    "for index, label in enumerate(labels):\n",
    "    y_data[index, label] = 1"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "id": "16e1252605baad73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:06:31.227380Z",
     "start_time": "2025-03-05T02:06:31.220081Z"
    }
   },
   "source": [
    "# Split the data in training and testing sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)"
   ],
   "outputs": [],
   "execution_count": 69
  },
  {
   "cell_type": "markdown",
   "id": "d25359b71ada240d",
   "metadata": {},
   "source": [
    "Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "92a5827046242b83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:05:57.913468Z",
     "start_time": "2025-03-05T02:05:57.900140Z"
    }
   },
   "source": [
    "# Define the loss function and network layers\n",
    "\n",
    "loss_function = CrossEntropyLossFunction()\n",
    "\n",
    "network_layers = [\n",
    "    # Input (Image Shape): 1 (Grayscale Channel) * 64 * 64. Output: 16 * 62 * 62.\n",
    "    Convolution(input_shape=(1, 64, 64), output_depth=16, kernel_size=3),\n",
    "    ReLU(),\n",
    "    # Max Pooling will divide shape by the stride. Output of Max Pooling: 16 * 31 * 31\n",
    "    MaxPooling(pool_size=2, stride=2),\n",
    "    \n",
    "    # Input: 16 * 31 * 31. Often, each Convolution Layer doubles the output_depth. Output: 32 * 29 * 29 \n",
    "    Convolution(input_shape=(16, 31, 31), output_depth=32, kernel_size=3),\n",
    "    ReLU(),\n",
    "    # Output: 32 * 14 * 14.\n",
    "    MaxPooling(pool_size=2, stride=2),\n",
    "\n",
    "    # Input: 32 * 14 * 14. Output: 64 * 12 * 12\n",
    "    Convolution(input_shape=(32, 14, 14), output_depth=64, kernel_size=3),\n",
    "    ReLU(),\n",
    "    # Output: 64 * 6 * 6.\n",
    "    MaxPooling(pool_size=2, stride=2),\n",
    "\n",
    "    # Flattening multidimensional array to 1D. Input: 64 * 6 * 6\n",
    "    Flatten(),\n",
    "    \n",
    "    FullyConnected(input_size=64 * 6 * 6, output_size=256),\n",
    "    ReLU(),\n",
    "    \n",
    "    # Input: 256. Output: 36 (Number of total labels).\n",
    "    FullyConnected(input_size=256, output_size=y_data.shape[1]),\n",
    "    Softmax()\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "id": "2e012277f1587d28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:05:58.667183Z",
     "start_time": "2025-03-05T02:05:58.664036Z"
    }
   },
   "source": "ASL_model = Network(network_layers, loss_function)",
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "id": "a7b31dbda54b4c1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:50:26.978976Z",
     "start_time": "2025-03-05T01:50:24.040517Z"
    }
   },
   "source": [
    "ASL_model.train(x_train, y_train, 20, 0.001)"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mASL_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.001\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/ComputerScience/CSC590MachineLearning/ASL-CNN/Model/Network.py:28\u001B[0m, in \u001B[0;36mNetwork.train\u001B[0;34m(self, x_train, y_train, epochs, learning_rate)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Iterate through each training sample\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(x_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n\u001B[0;32m---> 28\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;66;03m# Back propagate starting with error gradient\u001B[39;00m\n\u001B[1;32m     31\u001B[0m     grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss\u001B[38;5;241m.\u001B[39mbackward(y_train[i], output)\n",
      "File \u001B[0;32m~/Documents/ComputerScience/CSC590MachineLearning/ASL-CNN/Model/Network.py:17\u001B[0m, in \u001B[0;36mNetwork.predict\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     14\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnetwork:\n\u001B[0;32m---> 17\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[0;32m~/Documents/ComputerScience/CSC590MachineLearning/ASL-CNN/Layers/Convolution.py:32\u001B[0m, in \u001B[0;36mConvolution.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# Iterate through each output channel and accumulate the valid correlation value of the input channel with the associated kernels\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m output_channel \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_depth):\n\u001B[0;32m---> 32\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m input_channel \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_depth):\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput[output_channel] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m signal\u001B[38;5;241m.\u001B[39mcorrelate2d(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput[input_channel],\n\u001B[1;32m     34\u001B[0m                                                           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernels[output_channel, input_channel], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalid\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/signal/_signaltools.py:1848\u001B[0m, in \u001B[0;36mcorrelate2d\u001B[0;34m(in1, in2, mode, boundary, fillvalue)\u001B[0m\n\u001B[1;32m   1846\u001B[0m val \u001B[38;5;241m=\u001B[39m _valfrommode(mode)\n\u001B[1;32m   1847\u001B[0m bval \u001B[38;5;241m=\u001B[39m _bvalfromboundary(boundary)\n\u001B[0;32m-> 1848\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43m_sigtools\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convolve2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43min1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43min2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconj\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfillvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1850\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m swapped_inputs:\n\u001B[1;32m   1851\u001B[0m     out \u001B[38;5;241m=\u001B[39m out[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, ::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "75e49ce80b1aaa90",
   "metadata": {},
   "source": "Save and Retrieve the Model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:06:00.583093Z",
     "start_time": "2025-03-05T02:06:00.579657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "\"\"\"Save the trained model's weights and biases in a pickle file.\"\"\"\n",
    "def save_model(model, model_path):\n",
    "    with open(model_path, 'wb') as file:\n",
    "        pickle.dump(ASL_model, file)\n",
    "        \n",
    "\"\"\"Load the model from the pickle file.\"\"\"\n",
    "def get_model(model_path):\n",
    "    with open(model_path, 'rb') as model:\n",
    "        CNN = pickle.load(model)\n",
    "    return CNN"
   ],
   "id": "4fa528d71b4c2fd1",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Predict and Evaluate",
   "id": "d2d57eea885a62bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:06:34.663383Z",
     "start_time": "2025-03-05T02:06:34.659013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Gets true and predicted labels for a given image.\"\"\"\n",
    "def get_labels(image, index, CNN):\n",
    "    label = np.argmax(y_test[index])\n",
    "    prediction = CNN.predict(image)\n",
    "    pred_label = np.argmax(prediction)\n",
    "    \n",
    "    return label, pred_label"
   ],
   "id": "1cc69fe7bbeb262a",
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "id": "fdfc48ca009df4b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:06:35.010742Z",
     "start_time": "2025-03-05T02:06:35.007112Z"
    }
   },
   "source": [
    "\"\"\"Use the trained CNN to predict on a random image in the testing set.\"\"\"\n",
    "def predict(CNN):\n",
    "    rand_index = np.random.randint(0, len(x_test) - 1)\n",
    "    image = x_test[rand_index]\n",
    "    \n",
    "    label, pred_label = get_labels(image, rand_index, CNN)\n",
    "\n",
    "    print(\"True Label: \", classes[label])\n",
    "    print(\"Predicted Label: \", classes[pred_label])\n",
    "\n",
    "    plt.imshow(image[0], cmap='gray')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "id": "64f6d2d5a2d0188a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:06:35.354547Z",
     "start_time": "2025-03-05T02:06:35.352331Z"
    }
   },
   "source": [
    "def accuracy(CNN):\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        image = x_test[i]\n",
    "        label, pred_label = get_labels(image, i, CNN)\n",
    "\n",
    "        if pred_label == label:\n",
    "            cnt += 1\n",
    "\n",
    "    return (cnt / len(x_test)) * 100"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate 28x28 Image With 20 Epochs",
   "id": "399c18342c1c1a67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T02:06:39.572472Z",
     "start_time": "2025-03-05T02:06:36.584243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = '/Users/aaryanpatel/Documents/ComputerScience/CSC590MachineLearning/ASL-CNN/ASL_trained_model28x28.pkl'\n",
    "\n",
    "CNN_28 = get_model(model_path)\n",
    "predict(CNN_28)\n",
    "print(\"Accuracy of CNN with 28x28 Image and 20 Epochs: \", accuracy(CNN_28))"
   ],
   "id": "a2f3604c9d97244b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Label:  b\n",
      "Predicted Label:  b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of CNN with 28x28 Image and 20 Epochs:  95.62624254473161\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cae244bea45bdbc0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
