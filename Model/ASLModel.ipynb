{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e0d4027712622d",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:50:31.595259Z",
     "start_time": "2025-03-05T01:50:31.591880Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "be0ea784f803fef7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:50:32.149239Z",
     "start_time": "2025-03-05T01:50:32.147157Z"
    }
   },
   "source": [
    "from Model.Network import Network\n",
    "from Layers.MaxPooling import MaxPooling\n",
    "from Layers.FullyConnected import FullyConnected\n",
    "from Layers.Convolution import Convolution\n",
    "from Loss.CrossEntropyLossFunction import CrossEntropyLossFunction\n",
    "from Activation.Softmax import Softmax\n",
    "from Layers.Flatten import Flatten\n",
    "from Activation.ReLU import ReLU"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "eaaf6dd5e662fcb4",
   "metadata": {},
   "source": [
    "Preprocess Images"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "image_shape = (28,28)",
   "id": "608c4477bb7d8be"
  },
  {
   "cell_type": "code",
   "id": "c4dc02a6c920b49b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:51:27.465831Z",
     "start_time": "2025-03-05T01:51:27.461336Z"
    }
   },
   "source": [
    "\"\"\"Read, resize, and normalize the image.\"\"\"\n",
    "def preprocess_image(path):\n",
    "    data_sample = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    data_sample = cv2.resize(data_sample, image_shape)\n",
    "    data_sample = data_sample / 255.0\n",
    "    \n",
    "    return data_sample"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "e5f039b86c93814b",
   "metadata": {},
   "source": [
    "Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "87f3b5623be1a563",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:51:28.344543Z",
     "start_time": "2025-03-05T01:51:28.341250Z"
    }
   },
   "source": [
    "# Sort the folders in the dataset in alphabetical order\n",
    "data_path = '/Users/aaryanpatel/Documents/ComputerScience/CSC590MachineLearning/ASL-CNN/asl_dataset'\n",
    "classes = sorted(os.listdir(data_path))\n",
    "\n",
    "# Create dictionary mapping classes to indexes\n",
    "class_index_dict = {}\n",
    "for index, clas in enumerate(classes):\n",
    "    class_index_dict[clas] = index"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "1fe6916bb8f19b6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:51:29.716110Z",
     "start_time": "2025-03-05T01:51:28.782270Z"
    }
   },
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Extract the images and labels (using the created dictionary) of each subdirectory in the dataset\n",
    "for folder in classes:\n",
    "    folder_dir = os.path.join(data_path, folder)\n",
    "\n",
    "    for image in os.listdir(folder_dir):\n",
    "        img_path = os.path.join(folder_dir, image)\n",
    "\n",
    "        #image = preprocess_image(img_path)\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, image_shape)\n",
    "        image = image / 255.0\n",
    "\n",
    "        images.append(image)\n",
    "        labels.append(class_index_dict[folder])"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "16ce4530d3165e09",
   "metadata": {},
   "source": [
    "Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "d0c66ae7b4df5e5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:51:30.557126Z",
     "start_time": "2025-03-05T01:51:30.520166Z"
    }
   },
   "source": [
    "# Reshape the images to create the x_data\n",
    "\n",
    "x_data = np.array(images).reshape(-1, 1, image_shape[0], image_shape[1])"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "2da25a11f4869769",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:51:31.075085Z",
     "start_time": "2025-03-05T01:51:31.072367Z"
    }
   },
   "source": [
    "# One-hot-encode the labels to create the y_data\n",
    "\n",
    "y_data = np.zeros((len(labels), len(classes)))\n",
    "for index, label in enumerate(labels):\n",
    "    y_data[index, label] = 1"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "16e1252605baad73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:51:31.597592Z",
     "start_time": "2025-03-05T01:51:31.588446Z"
    }
   },
   "source": [
    "# Split the data in training and testing sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "d25359b71ada240d",
   "metadata": {},
   "source": [
    "Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "92a5827046242b83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T18:26:52.012478Z",
     "start_time": "2025-03-04T18:26:52.000188Z"
    }
   },
   "source": [
    "# Define the loss function and network layers\n",
    "\n",
    "loss_function = CrossEntropyLossFunction()\n",
    "\n",
    "network_layers = [\n",
    "    # Input (Image Shape): 1 (Grayscale Channel) * 64 * 64. Output: 16 * 62 * 62.\n",
    "    Convolution(input_shape=(1, 64, 64), output_depth=16, kernel_size=3),\n",
    "    ReLU(),\n",
    "    # Max Pooling will divide shape by the stride. Output of Max Pooling: 16 * 31 * 31\n",
    "    MaxPooling(pool_size=2, stride=2),\n",
    "    \n",
    "    # Input: 16 * 31 * 31. Often, each Convolution Layer doubles the output_depth. Output: 32 * 29 * 29 \n",
    "    Convolution(input_shape=(16, 31, 31), output_depth=32, kernel_size=3),\n",
    "    ReLU(),\n",
    "    # Output: 32 * 14 * 14.\n",
    "    MaxPooling(pool_size=2, stride=2),\n",
    "\n",
    "    # Input: 32 * 14 * 14. Output: 64 * 12 * 12\n",
    "    Convolution(input_shape=(32, 14, 14), output_depth=64, kernel_size=3),\n",
    "    ReLU(),\n",
    "    # Output: 64 * 6 * 6.\n",
    "    MaxPooling(pool_size=2, stride=2),\n",
    "\n",
    "    # Flattening multidimensional array to 1D. Input: 64 * 6 * 6\n",
    "    Flatten(),\n",
    "    \n",
    "    FullyConnected(input_size=64 * 6 * 6, output_size=256),\n",
    "    ReLU(),\n",
    "    \n",
    "    # Input: 256. Output: 36 (Number of total labels).\n",
    "    FullyConnected(input_size=256, output_size=y_data.shape[1]),\n",
    "    Softmax()\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "2e012277f1587d28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T18:26:52.639561Z",
     "start_time": "2025-03-04T18:26:52.637351Z"
    }
   },
   "source": "ASL_model = Network(network_layers, loss_function)",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "a7b31dbda54b4c1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:50:26.978976Z",
     "start_time": "2025-03-05T01:50:24.040517Z"
    }
   },
   "source": [
    "ASL_model.train(x_train, y_train, 20, 0.001)"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mASL_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.001\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/ComputerScience/CSC590MachineLearning/ASL-CNN/Model/Network.py:28\u001B[0m, in \u001B[0;36mNetwork.train\u001B[0;34m(self, x_train, y_train, epochs, learning_rate)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Iterate through each training sample\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(x_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n\u001B[0;32m---> 28\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;66;03m# Back propagate starting with error gradient\u001B[39;00m\n\u001B[1;32m     31\u001B[0m     grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss\u001B[38;5;241m.\u001B[39mbackward(y_train[i], output)\n",
      "File \u001B[0;32m~/Documents/ComputerScience/CSC590MachineLearning/ASL-CNN/Model/Network.py:17\u001B[0m, in \u001B[0;36mNetwork.predict\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     14\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnetwork:\n\u001B[0;32m---> 17\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[0;32m~/Documents/ComputerScience/CSC590MachineLearning/ASL-CNN/Layers/Convolution.py:32\u001B[0m, in \u001B[0;36mConvolution.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# Iterate through each output channel and accumulate the valid correlation value of the input channel with the associated kernels\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m output_channel \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_depth):\n\u001B[0;32m---> 32\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m input_channel \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_depth):\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput[output_channel] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m signal\u001B[38;5;241m.\u001B[39mcorrelate2d(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput[input_channel],\n\u001B[1;32m     34\u001B[0m                                                           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernels[output_channel, input_channel], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalid\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/signal/_signaltools.py:1848\u001B[0m, in \u001B[0;36mcorrelate2d\u001B[0;34m(in1, in2, mode, boundary, fillvalue)\u001B[0m\n\u001B[1;32m   1846\u001B[0m val \u001B[38;5;241m=\u001B[39m _valfrommode(mode)\n\u001B[1;32m   1847\u001B[0m bval \u001B[38;5;241m=\u001B[39m _bvalfromboundary(boundary)\n\u001B[0;32m-> 1848\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43m_sigtools\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convolve2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43min1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43min2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconj\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfillvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1850\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m swapped_inputs:\n\u001B[1;32m   1851\u001B[0m     out \u001B[38;5;241m=\u001B[39m out[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, ::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "75e49ce80b1aaa90",
   "metadata": {},
   "source": "Save and Retrieve the Model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:59:13.443920Z",
     "start_time": "2025-03-05T01:59:13.428230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "\"\"\"Save the trained model's weights and biases in a pickle file.\"\"\"\n",
    "def save_model(model, model_path):\n",
    "    with open(model_path, 'wb') as file:\n",
    "        pickle.dump(ASL_model, file)\n",
    "        \n",
    "\"\"\"Load the model from the pickle file.\"\"\"\n",
    "def get_model(model_path):\n",
    "    with open(model_path, 'rb') as model:\n",
    "        CNN = pickle.load(model)\n",
    "    return CNN\n"
   ],
   "id": "4fa528d71b4c2fd1",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Predict and Evaluate",
   "id": "d2d57eea885a62bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:59:14.817802Z",
     "start_time": "2025-03-05T01:59:14.814957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Gets true and predicted labels for a given image.\"\"\"\n",
    "def get_labels(image, index, CNN):\n",
    "    label = np.argmax(y_test[index])\n",
    "    prediction = CNN.predict(image)\n",
    "    pred_label = np.argmax(prediction)\n",
    "    \n",
    "    return label, pred_label"
   ],
   "id": "1cc69fe7bbeb262a",
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "fdfc48ca009df4b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:59:15.607036Z",
     "start_time": "2025-03-05T01:59:15.600796Z"
    }
   },
   "source": [
    "\"\"\"Use the trained CNN to predict on a random image in the testing set.\"\"\"\n",
    "def predict(CNN):\n",
    "    rand_index = np.random.randint(0, len(x_test) - 1)\n",
    "    image = x_test[rand_index]\n",
    "    \n",
    "    label, pred_label = get_labels(image, rand_index, CNN)\n",
    "\n",
    "    print(\"True Label: \", classes[label])\n",
    "    print(\"Predicted Label: \", classes[pred_label])\n",
    "\n",
    "    plt.imshow(image[0], cmap='gray')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "64f6d2d5a2d0188a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:59:24.202788Z",
     "start_time": "2025-03-05T01:59:24.196224Z"
    }
   },
   "source": [
    "def accuracy(CNN):\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        image = x_test[i]\n",
    "        label, pred_label = get_labels(image, i, CNN)\n",
    "\n",
    "        if pred_label == label:\n",
    "            cnt += 1\n",
    "\n",
    "    return (cnt / len(x_test)) * 100"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate 28x28 Image With 20 Epochs",
   "id": "399c18342c1c1a67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T01:59:28.298450Z",
     "start_time": "2025-03-05T01:59:25.170801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = '/Users/aaryanpatel/Documents/ComputerScience/CSC590MachineLearning/ASL-CNN/ASL_trained_model28x28.pkl'\n",
    "\n",
    "CNN_28 = get_model(model_path)\n",
    "print(predict(CNN_28))\n",
    "print(accuracy(CNN_28))"
   ],
   "id": "a2f3604c9d97244b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Label:  g\n",
      "Predicted Label:  g\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "96.42147117296223\n"
     ]
    }
   ],
   "execution_count": 46
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
